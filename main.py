import os
import gspread
from google.oauth2.service_account import Credentials
from dotenv import load_dotenv
import asyncio
import re
from typing import List, Dict, Optional
from datetime import datetime
from dateutil.relativedelta import relativedelta
from rapidfuzz import process, fuzz

from Firebase.firestore_handler import save_to_firestore, load_data_from_sheets_and_save_to_firestore, _load_data
from GoogleSheets.sheets import get_or_create_spreadsheet, write_data, read_data
from utils.logger import setup_logger

from Macro.market_growth import get_market_data_from_sheets, interpret_market_data

from Meso.circle_chart_collector import get_circle_chart
from Meso.melon_album_data_collector import get_album_data, get_artist_data, get_songs_data, get_target_artist_albums_list
from Meso.spotify_songs_data_collector import get_spotify_data, get_spotify_data_with_melon_data

from Micro.circlechart_album_sales import fetch_sales
from Micro.performance_data_collector import get_naver_concert_data
from Micro.broadcast_data_collector import get_naver_broadcast_data
from Micro.youtube_data_collector import get_youtube_videos
from Micro.albums_comments_analysis import analyze_album_comments

load_dotenv()
MELON_ID = os.getenv('MELON_ID')

# 로깅 설정
logger = setup_logger(__name__)

async def get_market_data_and_save_to_firestore():
    data: Optional[List[Dict]] = await get_market_data_from_sheets()
    if data is not None:
        logger.info(f"Data retrieved: {data}")
        try:
            # MarketGrowth 컬렉션에 데이터 저장
            await save_to_firestore("MarketGrowth", data)
            # interpret_market_data 호출로 생성된 코멘트 가져오기
            comments = await interpret_market_data(data)
            print(comments)

            if comments:
                try:
                    await save_to_firestore("AutoComments", {"comments": comments})
                    logger.info("Auto-Comments successfully saved to Firestore.")
                except Exception as e:
                    logger.error(f"Error saving Auto-Comments to Firestore: {e}")
            else:
                logger.warning("No comments generated by interpret_market_data.")
                
            logger.info("Data successfully saved to Firestore.")
        except Exception as e:
            logger.error(f"Error saving data to Firestore: {e}")
    else:
        logger.error("No data retrieved.")

async def get_circle_charts_and_save_to_firestore():
    # 지난 달의 YYYYMM 형식 날짜 계산
    last_month_date = datetime.now() - relativedelta(months=1)
    yyyymm = last_month_date.strftime("%Y%m")
    logger.info(f"Target date (last month in YYYYMM format): {yyyymm}")

    # 차트 데이터 가져오기
    result = await get_circle_chart(yyyymm)
    if not result:
        logger.error("Failed to retrieve chart data.")
        return

    # 차트 데이터 개수 로깅
    global_count = len(result.get("global", []))
    streaming_count = len(result.get("streaming", []))
    retail_count = len(result.get("retail", []))

    logger.info(f"Fetched CircleChart data for target date {yyyymm}:")
    logger.info(f"- Global entries: {global_count}")
    logger.info(f"- Streaming entries: {streaming_count}")
    logger.info(f"- Retail entries: {retail_count}")

    # Firestore에 CircleChart 데이터 저장
    circle_chart_data = {
        "global": result["global"],
        "streaming": result["streaming"],
        "retail": result["retail"],
        "target": yyyymm
    }

    try:
        await save_to_firestore("CircleCharts", circle_chart_data)
        logger.info(f"Successfully saved data for target {yyyymm} to CircleCharts collection.")
    except Exception as e:
        logger.error(f"Error saving CircleCharts data: {e}")

    # 차트 데이터에서 Melon 앨범 URL 추출 및 중복 제거
    melon_album_ids = set()
    for chart_type in ['global', 'streaming', 'retail']:
        for entry in result.get(chart_type, []):
            url = entry.get('melon_album_id')
            if url:
                melon_album_ids.add(url)
    melon_album_ids = list(melon_album_ids)

    async def fetch_and_save_album_data(album_id):
        try:
            album = await asyncio.to_thread(get_album_data, album_id)
            if album:
                await save_to_firestore("albums", album)
                logger.info("Successfully saved album data to Firestore.")

                # 아티스트 데이터 저장
                artist = await asyncio.to_thread(get_artist_data, album['artist_id'])
                if artist:
                    await save_to_firestore("artists", artist)
                    logger.info("Successfully saved artist data to Firestore.")

                # 트랙 데이터 저장
                tracks = await asyncio.to_thread(get_songs_data, album['tracks'], album)
                songs = await asyncio.to_thread(get_spotify_data_with_melon_data, tracks)
                if songs:
                    await save_to_firestore("songs", songs)
                    logger.info("Successfully saved songs data to Firestore.")
        except Exception as e:
            logger.error(f"Error processing album {album_id}: {e}")

    tasks = [fetch_and_save_album_data(album_id) for album_id in melon_album_ids]
    await asyncio.gather(*tasks)

async def get_target_album_data_and_save_to_firestore():
    target_artist_melon_id = MELON_ID
    
    artist = await asyncio.to_thread(get_artist_data, target_artist_melon_id)
    if artist:
        await save_to_firestore("artists", artist)
        logger.info("Successfully saved artist data to Firestore.")

        melon_album_ids = await asyncio.to_thread(get_target_artist_albums_list, target_artist_melon_id)

        async def fetch_and_save_album_data(album_id):    
            try:
                album = await asyncio.to_thread(get_album_data, album_id)
                if album:
                    await save_to_firestore("albums", album)
                    logger.info(f"Successfully saved album {album_id} data to Firestore.")

                    # 트랙 데이터 저장
                    try:
                        tracks = await asyncio.to_thread(get_songs_data, album['tracks'], album)
                        songs = await asyncio.to_thread(get_spotify_data_with_melon_data, tracks)
                        if songs:
                            await save_to_firestore("songs", songs)
                            logger.info(f"Successfully saved songs for album {album_id} to Firestore.")
                        else:
                            logger.warning(f"No songs data found for album {album_id}")
                    except Exception as track_error:
                        logger.error(f"Error processing tracks for album {album_id}: {track_error}")
            except Exception as e:
                logger.error(f"Error processing album {album_id}: {e}")

        tasks = [fetch_and_save_album_data(album_id) for album_id in melon_album_ids]
        await asyncio.gather(*tasks)
    else:
        logger.warning(f"No artist data found for Melon ID: {target_artist_melon_id}")

async def get_album_sales_and_update_firestore_album_data():
    sales_data = fetch_sales()
    saved_data = _load_data('albums',[('artist_id','==',MELON_ID)])

    def extract_album_name(album_title):
        match = re.search(r'\)\s*(.*)', album_title)
        if match:
            album_name = match.group(1).strip()
        else:
            album_name = album_title.strip()
        return album_name

    def preprocess_album_name(album_name):
        album_name = album_name.lower()
        album_name = re.sub(r'[`$begin:math:display$$end:math:display$]', '', album_name)
        album_name = ' '.join(album_name.split())
        return album_name
    
    sales_album_dict = {preprocess_album_name(item['album_name']): item for item in sales_data}
    sales_album_names = list(sales_album_dict.keys())
    
    for album in saved_data:
        # saved_data의 album_title에서 album_name 추출 후 전처리
        extracted_album_name = extract_album_name(album['album_title'])
        preprocessed_saved_album_name = preprocess_album_name(extracted_album_name)
        
        # Fuzzy Matching을 사용하여 sales_data에서 가장 유사한 album_name 찾기
        match, score, _ = process.extractOne(
            preprocessed_saved_album_name,
            sales_album_names,
            scorer=fuzz.WRatio
        )
        
        logger.info(f"Matching '{preprocessed_saved_album_name}' with '{match}' (Score: {score})")
        
        if score >= 80:
            # 매칭된 sales_data 항목 가져오기
            matched_sales = sales_album_dict.get(match)
            if matched_sales:
                # sales_data의 정보를 saved_data에 추가
                album['total_sales'] = matched_sales.get('total_sales', 0)
                album['total_sales_year'] = matched_sales.get('total_sales_year', '')
                album['total_sales_month'] = matched_sales.get('total_sales_month', '')
                album['seq_aoa'] = matched_sales.get('seq_aoa', '')
                logger.info(f"Updated album '{album['album_title']}' with sales data.")
        else:
            logger.warning(f"No suitable match found for '{preprocessed_saved_album_name}' (Best Score: {score})")
    
    await save_to_firestore('albums', saved_data)
    logger.info("Firestore update process completed.")

async def get_album_comments_keywords():
    analyze_result = analyze_album_comments()

    try:
        await save_to_firestore("AlbumCommentsAnalysis", analyze_result)
        logger.info(f"Successfully saved data for Album Comments Analysis")
    except Exception as e:
        logger.error(f"Error saving CircleCharts data: {e}")


async def get_youtube_data_and_save_to_firestore():
    loop = asyncio.get_event_loop()
    videos, comments = await loop.run_in_executor(None, get_youtube_videos)
    
    if videos:
        await save_to_firestore("YoutubeVideos", videos)
        logger.info("Successfully saved Youtube Videos data to Firestore.")
    
    if comments:
        await save_to_firestore("YoutubeComments", comments)
        logger.info("Successfully saved Youtube Comments data to Firestore.")

def get_naver_concert_data_and_save_to_googlesheet():
    
    load_dotenv()
    folder_id = os.getenv('PIPELINE_FOLDER_ID')
    if not folder_id:
        logger.error("환경 변수 'PIPELINE_FOLDER_ID'가 설정되지 않았습니다.")
        exit(1)

    spreadsheet_title = '공연 데이터'
    spreadsheet = get_or_create_spreadsheet(folder_id, spreadsheet_title)

    worksheet = spreadsheet.sheet1
    
    worksheet_data = worksheet.get_all_values()
    if not worksheet_data or worksheet_data == [[]]:
        headers = ["title", "concert_url", "image_url", "image_alt", "location", "start_period", "end_period", "artist_id", "artist_name_kor", "artist_name_eng", "melon_artist_id", "revenue"]
        worksheet.append_row(headers)
        logger.info("헤더를 추가했습니다.")
    else:
        logger.info("헤더가 이미 존재합니다.")

    data = get_naver_concert_data()
    existing_data = read_data(worksheet, start_row=2)
    existing_urls = set(row['concert_url'] for row in existing_data)

    new_data = [concert for concert in data if concert['concert_url'] not in existing_urls]
    start_row = len(worksheet_data) + 1

    if new_data:
        write_data(worksheet, new_data, start_row=start_row)
        logger.info(f"총 {len(new_data)}개의 새로운 공연 데이터를 스프레드시트에 추가했습니다.")
    else:
        logger.info("추가할 새로운 공연 데이터가 없습니다.")

async def load_performance_data_from_sheet_and_save_to_firestore():
    await load_data_from_sheets_and_save_to_firestore(spreadsheet_title = "공연 데이터", collection_name = "performance")

def get_naver_broadcast_data_and_save_to_googlesheet():
    load_dotenv()
    folder_id = os.getenv('PIPELINE_FOLDER_ID')
    if not folder_id:
        logger.error("환경 변수 'PIPELINE_FOLDER_ID'가 설정되지 않았습니다.")
        exit(1)

    spreadsheet_title = '방송 데이터'
    spreadsheet = get_or_create_spreadsheet(folder_id, spreadsheet_title)

    worksheet = spreadsheet.sheet1

    data = get_naver_broadcast_data()
    headers = ["title","event_url","image_url","image_alt","start_period","end_period","artist_id","artist_name_kor","artist_name_eng","melon_artist_id","revenue"]
    if data:
        headers = list(data[0].keys())
        worksheet_data = worksheet.get_all_values()

        if not worksheet_data or worksheet_data == [[]]:
            worksheet.append_row(headers)
            logger.info("헤더를 추가했습니다.")
        else:
            logger.info("헤더가 이미 존재합니다.")
    else:
        logger.warning("data가 비어 있습니다.")

    existing_data = read_data(worksheet, start_row=2)
    existing_urls = set(row['concert_url'] for row in existing_data)

    def convert_lists_to_strings(data):
        for key, value in data.items():
            if isinstance(value, list):
                data[key] = ', '.join(value)
        return data

    url_map = {}
    for event in data:
        event_url = event.get('event_url')
        if event_url in url_map:
            # 이미 존재하는 경우 artists를 병합
            url_map[event_url]['artists'] = ', '.join(
                {url_map[event_url]['artists'], event.get('artists')}
            )
        else:
            # 새 항목 추가 (리스트 형식은 문자열로 변환)
            url_map[event_url] = convert_lists_to_strings(event)

    new_data = list(url_map.values())
    start_row = len(worksheet_data) + 1

    if new_data:
        write_data(worksheet, new_data, start_row=start_row)
        logger.info(f"총 {len(new_data)}개의 새로운 방송 데이터를 스프레드시트에 추가했습니다.")
    else:
        logger.info("추가할 새로운 방송 데이터가 없습니다.")

async def load_performance_data_from_sheet_and_save_to_firestore():
    await load_data_from_sheets_and_save_to_firestore(spreadsheet_title = "방송 데이터", collection_name = "broadcast")

async def main():
    await load_performance_data_from_sheet_and_save_to_firestore()

if __name__ == '__main__':
    #get_naver_broadcast_data_and_save_to_googlesheet()
    asyncio.run(main())